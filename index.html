<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Wenjie Song </title> <meta name="author" content="Wenjie Song"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bit-inin-wj.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Wenjie Song </h1> <p class="desc"><a href="https://ac.bit.edu.cn/szdw/jsml/dhzdykzyjs1/7f7592439afd4af88117ad92d2351a75.htm" rel="external nofollow noopener" target="_blank">School of Automation, Beijing Institute of Technology</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 1024px) 149.1px, (min-width: 576px) 15vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.png?b9a92a6460f524879b88bc3034e0b3b1" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Wenjie Song is currently a Professor at the School of Automation, Beijing Institute of Technology. He received the B.Eng. degree in Automation from Beijing Institute of Technology in 2013, and the Ph.D. degree in Control Science and Engineering from Beijing Institute of Technology in 2019 (Supervisor: Mengyin Fu), and the PhD joint project from Princeton University in 2016-2017 (Supervisor: Alain L. Kornhauser). His research interests include: unmanned cluster intelligent decision-making, cognitive navigation in unknown space, and multi-robot cooperative control. In these areas, he has published more than 30 papers in IEEE TCSVT, IEEE TVT, IEEE TAES, JAS, ICRA, IROS and other journals and conferences.</p> </div> <div class="more-info"> <p>Room 619, Teaching building No. 6, School of Automation, BIT</p> <p>Haidian, Beijing 100081</p> <p>Email: songwj@bit.edu.cn</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 22, 2024</th> <td> PhD, MSc and undergraduate research assistant positions available. Please feel free to contact me through email. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 22, 2024</th> <td> 热烈祝贺本组24届研究生同学毕业！ </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/chen2024hierarchical-480.webp 480w,/assets/img/publication_preview/chen2024hierarchical-800.webp 800w,/assets/img/publication_preview/chen2024hierarchical-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/chen2024hierarchical.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="chen2024hierarchical.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2024hierarchical" class="col-sm-9"> <div class="title">Hierarchical Learning with Heuristic Guidance for Multi-task Assignment and Distributed Planning in Interactive Scenarios</div> <div class="author"> Siyuan Chen, Meiling Wang, and Wenjie Song </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Vehicles</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/10444986" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>A unified framework for multi-agent task assignment and distributed trajectory planning that can autonomously adapt to complex interactive environments and multi-task constraints has always been the bottleneck of unmanned cluster task. In multi-agent systems such as smart parking lots and smart intersections, tasks are time-varying with dynamically interactive agents, which cause the challenges such as inefficient assignment, spatiotemporal conflict and poor adaptive ability. Focusing on them, this paper proposes a hierarchical framework that combines centralized task assignment module with a multi-agent reinforcement learning based distributed trajectory planning module, which has a good scalability and task adaptability. The benefit of the proposed hierarchical framework is that it utilizes behavioral heuristic of congestion level and planning cost during assignment to motivate the appropriate assignment, which achieve an organic integration of multiple objectives. In terms of spatiotemporal conflicts for multi-agent, a weighted network structure is designed to capture dynamic obstacle information while introducing conflict constraints for collision avoidance policy optimization. Furthermore, in order to cope with changing tasks, re-assignment and re-planning mechanisms are incorporated into the framework, as well as the graph encoding layer which is adaptive to the uncertain tasks. Extensive experiments are conducted in autonomous parking scenarios to validate the effectiveness of the approach in task assignment and path conflict mitigation. Compared with other state of art methods, the task assignment and overall success rates have increased by 12.1% and 6.8%, respectively, with negligible computing time.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/li2024multi-480.webp 480w,/assets/img/publication_preview/li2024multi-800.webp 800w,/assets/img/publication_preview/li2024multi-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/li2024multi.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="li2024multi.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="li2024multi" class="col-sm-9"> <div class="title">Multi-Step Continuous Decision Making and Planning in Uncertain Dynamic Scenarios Through Parallel Spatio-Temporal Trajectory Searching</div> <div class="author"> Delun Li, Siyuan Cheng, Shaoyu Yang, Wenchao Huang, and Wenjie Song </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10636263" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/TspV19KdgNo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Autonomous driving in urban scenarios faces uncertain dynamic changes, especially in China, where a dense mixture of cars, cyclists and pedestrians travel together on roads with random uncertain behaviors and high-risk road crossing. This paper proposes a Multi-step Continuous Decision Making and Spatio-temporal Trajectory Planning framework to achieve stable continuous decision making and high-quality trajectory planning in such uncertain and highly dynamic environments. Firstly, a 3D spatio-temporal probabilistic map is constructed to represent the uncertain future driving environment. Based on the map, parallel spatio-temporal trajectory search is performed to obtain multi-strategy feasible spatio-temporal trajectories that satisfy the short-term deterministic and long-term uncertain environmental constraints. Then considering the continuity and consistency of decision making, risk-aware rolling-fusion of trajectory sequences is proposed, achieving efficient and exploratory far-end planning with a stable and safe near-end driving trajectory. To validate the proposed framework, we collected the Hard Case data from real Chinese urban roads, containing challenging scenarios such as dense traffic flows, mixed vehicle-pedestrian roads, and complex intersections, which are widely recognized barriers to the successful real-world deployment of autonomous driving. Moreover, the SMARTS simulator is used to build closed-loop simulation scenarios to verify the effectiveness of the framework. Experimental results show the superior performance of our proposed framework in complex uncertain dynamic scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mao2024multi.webp-480.webp 480w,/assets/img/publication_preview/mao2024multi.webp-800.webp 800w,/assets/img/publication_preview/mao2024multi.webp-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mao2024multi.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mao2024multi.webp" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mao2024multi" class="col-sm-9"> <div class="title">Multi-UAV Cooperative Motion Planning Under Global Spatio-Temporal Path Inspiration in Constraint-Rich Dynamic Environments</div> <div class="author"> Zihao Mao, Mingyu Hou, Herui Li, Yi Yang, and Wenjie Song </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Vehicles</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10582491" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/maozihaoo/Multi-UAV-Cooperative-Motion-Planning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>When applied in building rescue, forest search and other missions, UAV swarms often encounter challenges such as narrow space constraints and dynamic changes of obstacles, which leads to internal conflicts in the swarm or cause system chaos due to avoiding dynamic obstacles during the execution of tasks. These rigorous characteristics of the actual application scenarios and tasks always make global searching difficult to be optimized and local obstacle avoidance into deadlock. To solve the above problems, this paper introduces a hierarchical online collaborative planning framework inspired by global spatio-temporal paths. In order to reduce the solution complexity while dissolving the overall conflict, global rough searching is conducted for initial spatio-temporal guidance path. To overcome dynamic obstacles without affecting the system internal harmony, online conflict-trend-based clustering co-optimization inspired by the initial path is performed to achieve obstacle avoidance while improving scalability. Experimental tests were conducted in simulation environments with narrow pipelines and dynamic obstacles with comparison to current mainstream centralized and distributed methods. The results demonstrate that our work can generate smoother and safer trajectories with higher success rate in the constraint-rich dynamic environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wang2024risk-480.webp 480w,/assets/img/publication_preview/wang2024risk-800.webp 800w,/assets/img/publication_preview/wang2024risk-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/wang2024risk.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wang2024risk.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wang2024risk" class="col-sm-9"> <div class="title">Risk-Inspired Aerial Active Exploration for Enhancing Autonomous Driving of UGV in Unknown Off-Road Environments</div> <div class="author"> Rongchuan Wang, Mengyin Fu, Jing Yu, Yi Yang, and Wenjie Song </div> <div class="periodical"> <em>In 2024 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10610352" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Unknown area exploration is a crucial but challenging task for autonomous driving of unmanned ground vehicles (UGV) in unknown off-road environments. However, the exploration efficiency of a single UGV is low due to its limited sensing range. To solve this problem, this paper proposes a risk-inspired aerial active exploration system, which utilizes the flexibility and field of view advantages of Unmanned Aerial Vehicles (UAV) to guide the UGV in unknown off-road environments. Firstly, a fast terrain risk mapping method that can be used for both UAV and UGV is developed. This method efficiently combines quadtree and hash table data structure to enable UAV to analyze large scale terrain point cloud in real time. Based on the risk mapping result, a risk-inspired active exploration method is proposed to actively search a safe reference path for the UGV, which introduces terrain risk information into the process of travel point selection. Finally, the reference path is gradually generated and optimized, so that the UGV can safely and smoothly follow the path to the target location. Compared with single UGV exploration system, our approach reduces the overall path risk by 26.8% in simulated experiments, showing that the proposed system can enhance autonomous driving of the UGV and help it effectively avoid high-risk areas in unknown off-road environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hou2024self-480.webp 480w,/assets/img/publication_preview/hou2024self-800.webp 800w,/assets/img/publication_preview/hou2024self-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/hou2024self.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hou2024self.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="hou2024self" class="col-sm-9"> <div class="title">Self-supervised Monocular Depth Estimation for All-Day Images Based On Dual-Axis Transformer</div> <div class="author"> Shengyu Hou, Mengyin Fu, Rongchuan Wang, Yi Yang, and Wenjie Song </div> <div class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10539960" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>All-day self-supervised monocular depth estimation has strong practical significance for autonomous systems to continuously perceive the 3D information of the world. However, night-time scenes pose challenges of weak texture and violating the brightness consistency assumption due to low illumination and varying lighting, respectively, which easily leads to most existing self-supervised models only being able to handle day-time scenes. To address this problem, we propose a self-supervised monocular depth estimation unified framework that can handle all-day scenarios, which has three features: (1) an Illumination Compensation PoseNet (ICP) is designed, which is based on the classic Phong illumination theory and compensates for lighting changes in adjacent frames by estimating per-pixel transformations; (2) a Dual-Axis Transformer (DAT) block is proposed as the backbone network of the depth encoder, which infers the depth of local low-illumination areas through spatial-channel dual-dimensional global context information of night-time images; (3) a cross-layer Adaptive Fusion Module (AFM) is introduced between multiple DAT blocks, which learns attention weights between different layer features and adaptively fuses cross-layer features using the learned weights, enhancing the complementarity of different layer features. This work was evaluated on multiple datasets, including: RobotCar, Waymo and KITTI datasets, achieving state-of-the-art results in both day-time and night-time scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> </div> <div id="wang2024traversability" class="col-sm-9"> <div class="title">Traversability Estimation for Off-Road Autonomous Driving Under Ego-Motion Uncertainty</div> <div class="author"> Kai Wang, Meiling Wang, Rongchuan Wang, Chaoyang Zhai, and Wenjie Song </div> <div class="periodical"> <em>IEEE Sensors Journal</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10382710" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The accurate and stable estimation of traversability is a crucial task for unmanned ground vehicle (UGV) driving in off-road environments. However, the complexity of off-road environments increases the difficulty of the task. Moreover, the stability of traversability estimation is adversely affected by ego-motion uncertainty caused by the violent jolts when the UGV is traveling fast on uneven surfaces. The lack of prior information also poses a significant challenge to the task. To address these challenges, this article proposes a novel framework for cost map (CM) generation, which uses light detection and ranging (LiDAR)-inertial odometry (LIO) and historically observed frames to generate local CMs with no need for any prior information. To describe the traversability of complex environments, we design a cost calculation method that includes a variety of factors affecting UGV driving. Not only terrain features such as slope and roughness, but also potential slip risks are considered in it. In consideration of ego-motion uncertainty, terrain continuity is modeled as a spatial constraint to enhance sparse laser scans, and historical observations are fused to filter out noises in the temporal dimension. Real-world experimental results demonstrate that the proposed method can generate stable CM with detailed traversability descriptions even with violent UGV jolts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/chen2023multi-480.webp 480w,/assets/img/publication_preview/chen2023multi-800.webp 800w,/assets/img/publication_preview/chen2023multi-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/chen2023multi.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="chen2023multi.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2023multi" class="col-sm-9"> <div class="title">Multi-Agent Reinforcement Learning-Based Decision Making for Twin-Vehicles Cooperative Driving in Stochastic Dynamic Highway Environments</div> <div class="author"> Siyuan Chen, Meiling Wang, Wenjie Song, Yi Yang, and Mengyin Fu </div> <div class="periodical"> <em>IEEE Transactions on Vehicular Technology</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10123696" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In the past decade, reinforcement learning (RL) has achieved encouraging results in autonomous driving, especially in well-structured and regulated highway environments. However, few researches pay attention to RL-based multiple-vehicles cooperative driving, which is much more challenging because of dynamic real-time interactions and transient scenarios. This article proposes a Multi-Agent Reinforcement Learning (MARL) based twin-vehicles cooperative driving decision making method which achieves the generalization adaptation of the RL method in highly dynamic highway environments and enhances the flexibility and effectiveness of collaborative decision making system. The proposed fair cooperative MARL method pays equal attention to the individual intelligence and the cooperative performance, and employs a stable estimation method to reduce the propagation of overestimated joint Q -values between agents. Thus, the twin-vehicles system strikes a balance between maintaining formation and free overtaking in dynamic highway environments, to intelligently adapt to different scenarios, such as heavy traffic, loose traffic, even some emergency. Targeted experiments show that our method has strong cooperative performance, also further increases the possibility of creating a harmonious driving environment.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wang2023aerial-480.webp 480w,/assets/img/publication_preview/wang2023aerial-800.webp 800w,/assets/img/publication_preview/wang2023aerial-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/wang2023aerial.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wang2023aerial.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wang2023aerial" class="col-sm-9"> <div class="title">Aerial-Ground Collaborative Continuous Risk Mapping for Autonomous Driving of Unmanned Ground Vehicle in Off-Road Environments</div> <div class="author"> Rongchuan Wang, Kai Wang, Wenjie Song, and Mengyin Fu </div> <div class="periodical"> <em>IEEE Transactions on Aerospace and Electronic Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10241990" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Terrain risk estimation has always been a crucial but challenging task for autonomous driving of unmanned ground vehicles (UGV) in off-road environments. The map with dense and accurate risk information can help UGV avoid special obstacles such as steep slopes, pits, and ditches while path planning. To solve this problem, this article proposes an aerial-ground collaboration system for continuous risk mapping in off-road environments, utilizing the flexibility and perspective advantages of unmanned aerial vehicles (UAVs). In the system, UAV carries a downward 2-D laser and a visual inertial system to construct a bird’s eye map, while UGV is equipped with a 3-D LiDAR for local mapping. In detail, our system focuses on two aspects, which are cross-view map matching and collaborative continuous risk mapping. For cross-view map matching, risk values for point clouds from aerial and ground platforms are calculated and used for terrain segmentation. Then, point-to-voxel residual is built for terrain point sets to accelerate matching. For collaborative continuous risk mapping, an entropy based probabilistic fusion is proposed for accurate risk fusion of overlapping cells. Then, a Bayesian generalized kernel inference algorithm is adapted to predict risk values of the remaining unknown areas. Simulation and real-world experimental results show that the dense and continuous global risk map constructed by the proposed system can effectively assist UGV for path planning in off-road environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/chen2023conflict-480.webp 480w,/assets/img/publication_preview/chen2023conflict-800.webp 800w,/assets/img/publication_preview/chen2023conflict-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/chen2023conflict.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="chen2023conflict.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2023conflict" class="col-sm-9"> <div class="title">Conflict-constrained Multi-agent Reinforcement Learning Method for Parking Trajectory Planning</div> <div class="author"> Siyuan Chen, Meiling Wang, Yi Yang, and Wenjie Song </div> <div class="periodical"> <em>In 2023 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10160698" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Automated Valet Parking (AVP) has been exten-sively researched as an important application of autonomous driving. Considering the high dynamics and density of real parking lots, a system that considers multiple vehicles simultaneously is more robust and efficient than a single vehicle setting as in most studies. In this paper, we propose a dis-tributed Multi-agent Reinforcement Learning(MARL) method for coordinating multiple vehicles in the framework of an AVP system. This method utilizes traditional trajectory planning to accelerate the learning process and introduces collision conflict constraints for policy optimization to mitigate the path conflict problem. In contrast to other centralized multi-agent path finding methods, the proposed approach is scalable, distributed, and adapts to dynamic stochastic scenarios. We train the models in random scenarios and validate in several artificially designed complex parking scenarios where vehicles are always disturbed by dynamic and static obstacles. Experimental results show that our approach mitigates path conflicts and excels in terms of success rate and efficiency.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> </div> <div id="hou2023joint" class="col-sm-9"> <div class="title">Joint Learning of Image Deblurring and Depth Estimation Through Adversarial Multi-Task Network</div> <div class="author"> Shengyu Hou, Mengyin Fu, and Wenjie Song </div> <div class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10136232" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Self-supervised monocular depth estimation methods have achieved remarkable results on natural clear images. However, it is still a serious challenge to directly recover depth information from blurred images caused by long-time exposure while camera fast moving. To address this issue, we propose a unified framework for simultaneous deblurring and depth estimation (SDDE), which has higher coupling performance and flexibility compared with the simple concatenation strategy of deblurring model and depth estimation model. This framework mainly benefits from three features: 1) a novel Task-aware Fusion Module (TFM) to adaptively select the most relevant intermediate shared features for the dual decoder network by aggregating multi-scale features, 2) a unique Spatial Interaction Module (SIM) to learn higher-order representation in the encoder stage to better describe complex boundaries of different classes in high-dimensional space, and focuses on the task-related region by modeling the pairwise spatial correlation of the holistic tensor, 3) a Priors-Based Composite Regularization term to jointly optimize the shared encoder-dual decoder network. This work was evaluated on multiple datasets, including: Stereo blur, KITTI,NYUv2, REDS and our own large-scale stereo blur dataset, resulting in state-of-the-art results for depth estimation and image deblurring, respectively.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/song2022action-480.webp 480w,/assets/img/publication_preview/song2022action-800.webp 800w,/assets/img/publication_preview/song2022action-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/song2022action.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="song2022action.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="song2022action" class="col-sm-9"> <div class="title">Action-State Joint Learning-Based Vehicle Taillight Recognition in Diverse Actual Traffic Scenes</div> <div class="author"> Wenjie Song, Shixian Liu, Ting Zhang, Yi Yang, and Mengyin Fu </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9756944" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>As the vital factor of vehicle behavior understanding and prediction, vehicle taillight recognition is an important technology for autonomous driving, especially in diverse actual traffic scenes full of dynamic interactive traffic participants. However, in practical application, it always faces many challenges, such as ‘variable lighting conditions’, ‘non-uniform taillight standards’ and ‘random relative observation pose’, which lead to few mature solutions in current common autopilot systems. This work proposes an action-state joint learning-based vehicle taillight recognition method on the basis of vehicles detection and tracking, which takes both taillight state features and time series features into account, consequently getting practicable results even in complex actual scenes. In detail, vehicle tracking sequence is used as input and split into pieces through a sliding window. Then, a CNN-LSTM model is applied to simultaneously identify the action features of brake lights and turn signals, dividing taillight actions into five categories: None, Brake_on, Brake_off, Left_turn, Right_turn. Next, the brightness of high-position brake light is extracted through semantic segmentation and combined with taillight actions to form higher-level features for taillight state sequence analysis. Finally, an undirected graph model is used to establish the long-term dependence between successive pieces by analysing the higher-level features, thus inferring the continuous taillight state into: off , brake , left , right . Datasets including daytime, nighttime, congested road, highway, etc. were collected, tested and published in our work to demonstrate its effectiveness and practicability.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/qian2022generative-480.webp 480w,/assets/img/publication_preview/qian2022generative-800.webp 800w,/assets/img/publication_preview/qian2022generative-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/qian2022generative.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="qian2022generative.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="qian2022generative" class="col-sm-9"> <div class="title">Generative Design of XingT, A Human-sized Heavy-duty Bipedal Robot</div> <div class="author"> Yizhao Qian, Peiyu Yang, Weicheng Liu, Shuangyuan Sun, Mengyin Fu, and Wenjie Song </div> <div class="periodical"> <em>In 2022 IEEE International Conference on Robotics and Biomimetics (ROBIO)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10011733" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In order to serve humanity better in the disabled assisting, transportation, rescue, and other aspects, a human-sized bionic bipedal structure with low inertia and high-load capacity is presented. The designed robot named XingT adopts a non-coaxial five-link leg structure, after kinematic modeling analysis and structural comparison, being able to bear a load beyond its weight. Besides, bionic tibia modules and passive compliant units are adopted, effectively absorbing motion impact in high-load and strong-impact scenarios. In addition, with structural design and simulation analysis, the proposed five-link structure can realize multi-mode switching, which can adapt to high load application in the convex five-link form and switch to concave five-link mode for light and flexible walking effect. Results of prototype and simulation experiments showed that it can reduce impacts by 67% and increase the load performance by 22.3%, which verifies its structural performance for future practical application.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/zhang2021unified-480.webp 480w,/assets/img/publication_preview/zhang2021unified-800.webp 800w,/assets/img/publication_preview/zhang2021unified-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/zhang2021unified.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="zhang2021unified.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2021unified" class="col-sm-9"> <div class="title">A Unified Framework Integrating Decision Making and Trajectory Planning Based on Spatio-Temporal Voxels for Highway Autonomous Driving</div> <div class="author"> Ting Zhang, Wenjie Song, Mengyin Fu, Yi Yang, Xiaohui Tian, and Meiling Wang </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9479862" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Intelligent decision making and efficient trajectory planning are closely related in autonomous driving technology, especially in highway environment full of dynamic interactive traffic participants. This work integrates them into a unified hierarchical framework with long-term behavior planning (LTBP) and short-term dynamic planning (STDP) running in two parallel threads with different horizon, consequently forming a closed-loop maneuver and trajectory planning system that can react to the dynamic environment effectively and efficiently. In LTBP, a novel voxel structure and the ‘voxel expansion’ algorithm are proposed for the generation of driving corridors in 3D configuration, which involves the prediction states of surrounding vehicles. By using Dijkstra search, the maneuver with minimal cost is determined in form of voxel sequences, then a quadratic programming (QP) problem is constructed for solving the optimal trajectory. And in STDP, another small-scaled QP problem is performed to track or adjust the reference trajectory from LTBP in response to the dynamic obstacles. Meanwhile, a Responsibility-Sensitive Safety (RSS) Checker keeps running at high frequency for real-time feedback to ensure security. Experiments on real data collected in different highway scenarios demonstrate the effectiveness and efficiency of our work.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fu2021trajectory-480.webp 480w,/assets/img/publication_preview/fu2021trajectory-800.webp 800w,/assets/img/publication_preview/fu2021trajectory-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/fu2021trajectory.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fu2021trajectory.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="fu2021trajectory" class="col-sm-9"> <div class="title">Trajectory Prediction-Based Local Spatio-Temporal Navigation Map for Autonomous Driving in Dynamic Highway Environments</div> <div class="author"> Mengyin Fu, Ting Zhang, Wenjie Song, Yi Yang, and Meiling Wang </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9357411" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Autonomous driving, including intelligent decision-making and path planning, in dynamic environments (like highway) is significantly more difficult than the navigation in static scenarios because of the additional time dimension. Therefore, correlating the time dimension and the space dimension through prediction to create a spatio-temporal navigation map can make decision-making and path planning in such kinds of environment much easier. In this article, NGSIM data is analysed and processed from the perspective of the ego-vehicle (using the data as an ego-vehicle’s perception results). Based on the data, we develop an LSTM (Long-Short Term Memory)-based framework to predict possible trajectories of multiple surrounding vehicles within a certain range of the ego-vehicle. Then, the multiple predicted trajectories in a series of continuous dynamic highway scenes are projected into a spatio-temporal domain to create an octree map. Thus, dynamic targets and static obstacles can be unified into the same domain or map so that the dynamic disturbance problem for autonomous driving in highway environments can be resolved. Experimental results show that the proposed model is capable of predicting all the future trajectories around the ego-vehicle efficiently and the corresponding spatio-temporal map can be generated accurately in different dynamic scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/zhang2020trajectory-480.webp 480w,/assets/img/publication_preview/zhang2020trajectory-800.webp 800w,/assets/img/publication_preview/zhang2020trajectory-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/zhang2020trajectory.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="zhang2020trajectory.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2020trajectory" class="col-sm-9"> <div class="title">Trajectory Planning Based on Spatio-Temporal Map With Collision Avoidance Guaranteed by Safety Strip</div> <div class="author"> Ting Zhang, Mengyin Fu, Wenjie Song, Yi Yang, and Meiling Wang </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9190057" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Trajectory planning for the unmanned vehicle in the complex environment has always been a challenging task. Planned trajectory with the corresponding target velocity or acceleration sequence must be collision-free guaranteed and as comfortable as possible on the premise of obeying the traffic rules and interaction with other dynamic social vehicles. To meet this requirement, this paper proposes a framework for trajectory planning based on spatio-temporal map. Due to the time layer architecture in the map, the trajectory can be generated with velocity and acceleration simultaneously, and the whole trajectory is constrained within a ‘safety strip’, resulting in an efficient and safety guaranteed trajectory. The framework is composed of three sections: rough search, fine optimization and safety strip-based collision avoidance. For rough search, we propose an improved A* algorithm implemented in the discrete time layer to find out the suboptimal states efficiently. In fine optimization, the B-spline curve is exploited to connect the searched states into a continuous trajectory. And the optimal control points of B-spline are further grouped into several segments, forming the safety strip which is actually the distribution space of the planned trajectory. If necessary, an adjustment will be applied to keep the strip away from the collision zone, making the entire trajectory completely collision-free. Experiments on both public dataset and self-driving simulator show that the proposed framework can adapt to different kinds of complex traffic scenes well.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/zhang2021vehicle-480.webp 480w,/assets/img/publication_preview/zhang2021vehicle-800.webp 800w,/assets/img/publication_preview/zhang2021vehicle-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/zhang2021vehicle.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="zhang2021vehicle.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2021vehicle" class="col-sm-9"> <div class="title">Vehicle Motion Prediction at Intersections Based on the Turning Intention and Prior Trajectories Model</div> <div class="author"> Ting Zhang, Wenjie Song, Mengyin Fu, Yi Yang, and Meiling Wang </div> <div class="periodical"> <em>IEEE/CAA Journal of Automatica Sinica</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9416981" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Intersections are quite important and complex traffic scenarios, where the future motion of surrounding vehicles is an indispensable reference factor for the decision-making or path planning of autonomous vehicles. Considering that the motion trajectory of a vehicle at an intersection partly obeys the statistical law of historical data once its driving intention is determined, this paper proposes a long short-term memory based (LSTM-based) framework that combines intention prediction and trajectory prediction together. First, we build an intersection prior trajectories model (IPTM) by clustering and statistically analyzing a large number of prior traffic flow trajectories. The prior trajectories model with fitted probabilistic density is used to approximate the distribution of the predicted trajectory, and also serves as a reference for credibility evaluation. Second, we conduct the intention prediction through another LSTM model and regard it as a crucial cue for a trajectory forecast at the early stage. Furthermore, the predicted intention is also a key that is associated with the prior trajectories model. The proposed framework is validated on two publically released datasets, next generation simulation (NGSIM) and INTERACTION. Compared with other prediction methods, our framework is able to sample a trajectory from the estimated distribution, with its accuracy improved by about 20%. Finally, the credibility evaluation, which is based on the prior trajectories model, makes the framework more practical in the real-world applications.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/chen2020stabilization-480.webp 480w,/assets/img/publication_preview/chen2020stabilization-800.webp 800w,/assets/img/publication_preview/chen2020stabilization-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/chen2020stabilization.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="chen2020stabilization.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2020stabilization" class="col-sm-9"> <div class="title">Stabilization Approaches for Reinforcement Learning-Based End-to-End Autonomous Driving</div> <div class="author"> Siyuan Chen, Meiling Wang, Wenjie Song, Yi Yang, Yujun Li, and Mengyin Fu </div> <div class="periodical"> <em>IEEE Transactions on Vehicular Technology</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9028159/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Deep reinforcement learning (DRL) has been successfully applied to end-to-end autonomous driving, especially in simulation environments. However, common DRL approaches used in complex autonomous driving scenarios sometimes are unstable or difficult to converge. This paper proposes two approaches to improve the stability of the policy model training with as few manual data as possible. For the first approach, reinforcement learning is combined with imitation learning to train a feature network with a small amount of manual data for parameters initialization. For the second approach, an auxiliary network is added to the reinforcement learning framework, which can leverage the real-time measurement information to deepen the understanding of environment, without any guide of demonstrators. To verify the effectiveness of these two approaches, simulations in image information-based and lidar information-based end-to-end autonomous driving systems are conducted, respectively. These approaches are not only tested in the virtual game world, but also applied in Gazebo, in which we build a 3D world based on the real vehicle model of Ranger XP900 platform, the real 3D obstacle model, and the real motion constraints with inertial characteristics, so as to ensure that the trained end-to-end autonomous driving model is more suitable for the real world. Experimental results show that the performance is increased by over 45% in the virtual game world, and can converge quickly and stably in Gazebo in which previous methods can hardly converge.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%6F%6E%67%77%6A@%62%69%74.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=HsmLQ40AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Feel free to contact me via email! </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wenjie Song. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-linux\u670d\u52a1\u5668\u4f7f\u7528\u624b\u518c",title:"linux\u670d\u52a1\u5668\u4f7f\u7528\u624b\u518c",description:"linux\u670d\u52a1\u5668\u5e38\u7528\u547d\u4ee4&amp;\u5e38\u89c1\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2024/linux-basic/"}},{id:"news-\u70ed\u70c8\u795d\u8d3a\u672c\u7ec424\u5c4a\u7814\u7a76\u751f\u540c\u5b66\u6bd5\u4e1a",title:"\u70ed\u70c8\u795d\u8d3a\u672c\u7ec424\u5c4a\u7814\u7a76\u751f\u540c\u5b66\u6bd5\u4e1a\uff01",description:"",section:"News"},{id:"news-phd-msc-and-undergraduate-research-assistant-positions-available-please-feel-free-to-contact-me-through-email",title:"PhD, MSc and undergraduate research assistant positions available. Please feel free to contact...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%6F%6E%67%77%6A@%62%69%74.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=HsmLQ40AAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>